library(reshape2)
library(dplyr)
library(lsr)
library(ggplot2)
library(caret)
# set cd
setwd("/Users/alex/Documents/GitHub/Visual-Similarity/results/final2/")
filelist <- list.files("./", pattern = "*.csv")
n = 0
df.filelist <- list()
for (file_n in filelist){
n = n + 1
df <- read_csv(file_n, col_types = cols(file_loc = col_skip()))
df.filelist[[n]] <- df
}
split_into_2 <- function(df, loc, which_half){
if (which_half == 1){
df1 <- df[row.names(df) %in% 1:loc, ]
return(df1)
}
else if (which_half == 2) {
df2 <- df[row.names(df) %in% (loc+1):nrow(df), ]
return(df2)
}
else {
print("No Valid which_half input")
}
}
# set cd
setwd("/Users/alex/Documents/GitHub/Visual-Similarity/results/final2/")
filelist <- list.files("./", pattern = "*.csv")
n = 0
df.filelist <- list()
for (file_n in filelist){
n = n + 1
df <- read_csv(file_n, col_types = cols(file_loc = col_skip()))
df.filelist[[n]] <- df
}
split_into_2 <- function(df, loc, which_half){
if (which_half == 1){
df1 <- df[row.names(df) %in% 1:loc, ]
return(df1)
}
else if (which_half == 2) {
df2 <- df[row.names(df) %in% (loc+1):nrow(df), ]
return(df2)
}
else {
print("No Valid which_half input")
}
}
normalize_df <- function(df) {
# Find the maximum and minimum values for each column in the dataframe
max_vals <- apply(df, 2, max)
min_vals <- apply(df, 2, min)
# Subtract the minimum value from each column
df_sub <- sweep(df, 2, min_vals, `-`)
# Divide each column by its range
range_vals <- max_vals - min_vals
df_normalized <- sweep(df_sub, 2, range_vals, `/`)
return(df_normalized)
}
# split raw data by condition
symbol1 <- split_into_2(df.filelist[[1]], 60, 1)
german1 <- split_into_2(df.filelist[[1]], 60, 2)
symbol2 <- split_into_2(df.filelist[[2]], 60, 1)
english2 <- split_into_2(df.filelist[[2]], 60, 2)
symbol3 <- split_into_2(df.filelist[[3]], 59, 1)
english3 <-split_into_2(df.filelist[[3]], 59, 2)
falsefont4 <-split_into_2(df.filelist[[4]], 84, 1)
german4 <- split_into_2(df.filelist[[4]], 84, 2)
chinese5 <- split_into_2(df.filelist[[5]], 60, 1)
korean5 <- split_into_2(df.filelist[[5]], 60, 2)
chinese6 <- split_into_2(df.filelist[[6]], 40, 1)
korean6 <- split_into_2(df.filelist[[6]], 40, 2)
chinese7 <- split_into_2(df.filelist[[7]], 120, 1)
korean7 <- split_into_2(df.filelist[[7]], 120, 2)
# put all data together by condition
cond_list <- list(symbol1, german1, symbol2, english2, symbol3, english3,
falsefont4, german4, chinese5, korean5,
chinese6, korean6, chinese7, korean7)
# make a null normalized mean list
norm_mean_list <- data.frame(matrix(data = NA, nrow = 14, ncol = 6))
colnames(norm_mean_list) <- c("condition", "obj_num", "disc_strk", "strk_sum", "junc_sum", "PC")
norm_mean_list$condition <- c('symbol1', 'german1', 'symbol2', 'english2', 'symbol3', 'english3',
'falsefont4', 'german4', 'chinese5', 'korean5',
'chinese6', 'korean6', 'chinese7', 'korean7')
for (cond_i in 1:14){
cond_raw_i <- (cond_list[[cond_i]])
a <- normalize_df(cond_raw_i[, 2:6])
b <- cond_raw_i[, 1]
norm_cond_i <- cbind(a,b)
for (col_j in 2:6){
mean_i <- mean(norm_cond_i[, col_j])
norm_mean_list[cond_i, col_j] <- mean_i
}
}
norm_3 <- norm_mean_list
View(norm_3)
cond_list[[2]]
View(norm_3)
norm_mean_list
norm_cond_i
for (cond_i in 1:14){
cond_raw_i <- (cond_list[[cond_i]])
a <- normalize_df(cond_raw_i[, 2:6])
b <- cond_raw_i[, 1]
norm_cond_i <- cbind(b,a)
for (col_j in 2:6){
mean_i <- mean(norm_cond_i[, col_j])
norm_mean_list[cond_i, col_j] <- mean_i
}
}
norm_3 <- norm_mean_list
View(norm_3)
?rma
mod = metacont(
n.early,
mean.early.E64,
sd.early.E64,
n.late,
mean.late.E64,
sd.late.E64,
data = meta,
studlab = meta$author,
effect = "hedgesg",
method = "REML")
library(readr)
library(reshape2)
library(dplyr)
library(lsr)
library(ggplot2)
library(caret)
# set cd
setwd("/Users/alex/Documents/GitHub/Visual-Similarity/results/final2/")
filelist <- list.files("./", pattern = "*.csv")
n = 0
df.filelist <- list()
for (file_n in filelist){
n = n + 1
df <- read_csv(file_n, col_types = cols(file_loc = col_skip()))
df.filelist[[n]] <- df
}
split_into_2 <- function(df, loc, which_half){
if (which_half == 1){
df1 <- df[row.names(df) %in% 1:loc, ]
return(df1)
}
else if (which_half == 2) {
df2 <- df[row.names(df) %in% (loc+1):nrow(df), ]
return(df2)
}
else {
print("No Valid which_half input")
}
}
normalize_df <- function(df) {
# Find the maximum and minimum values for each column in the dataframe
max_vals <- apply(df, 2, max)
min_vals <- apply(df, 2, min)
# Subtract the minimum value from each column
df_sub <- sweep(df, 2, min_vals, `-`)
# Divide each column by its range
range_vals <- max_vals - min_vals
df_normalized <- sweep(df_sub, 2, range_vals, `/`)
return(df_normalized)
}
# split raw data by condition
symbol1 <- split_into_2(df.filelist[[1]], 60, 1)
german1 <- split_into_2(df.filelist[[1]], 60, 2)
symbol2 <- split_into_2(df.filelist[[2]], 60, 1)
english2 <- split_into_2(df.filelist[[2]], 60, 2)
symbol3 <- split_into_2(df.filelist[[3]], 59, 1)
english3 <-split_into_2(df.filelist[[3]], 59, 2)
falsefont4 <-split_into_2(df.filelist[[4]], 84, 1)
german4 <- split_into_2(df.filelist[[4]], 84, 2)
chinese5 <- split_into_2(df.filelist[[5]], 60, 1)
korean5 <- split_into_2(df.filelist[[5]], 60, 2)
chinese6 <- split_into_2(df.filelist[[6]], 40, 1)
korean6 <- split_into_2(df.filelist[[6]], 40, 2)
chinese7 <- split_into_2(df.filelist[[7]], 120, 1)
korean7 <- split_into_2(df.filelist[[7]], 120, 2)
# prepare a null mean list
mean_list <- data.frame(matrix(ncol = 6, nrow = 14))
colnames(mean_list) <- c("condition", "obj_num", "disc_strk", "strk_sum", "junc_sum", "PC")
mean_list$condition <- c('symbol1', 'german1', 'symbol2', 'english2', 'symbol3', 'english3',
'falsefont4', 'german4', 'chinese5', 'korean5',
'chinese6', 'korean6', 'chinese7', 'korean7')
# put all data together by condition
cond_list <- list(symbol1, german1, symbol2, english2, symbol3, english3,
falsefont4, german4, chinese5, korean5,
chinese6, korean6, chinese7, korean7)
for (cond_i in 1:14){
for (col_j in 2:6){
mean_ij <- mean(cond_list[[cond_i]][[col_j]])
mean_list[cond_i, col_j] <- mean_ij
}
}
# make a null normalized mean list
norm_mean_list <- data.frame(matrix(data = NA, nrow = 14, ncol = 6))
norm_mean_list[, 2:6] <- normalize_df(mean_list[ , 2:6])
colnames(norm_mean_list) <- c("condition", "obj_num", "disc_strk", "strk_sum", "junc_sum", "PC")
norm_mean_list$condition <- c('symbol1', 'german1', 'symbol2', 'english2', 'symbol3', 'english3',
'falsefont4', 'german4', 'chinese5', 'korean5',
'chinese6', 'korean6', 'chinese7', 'korean7')
norm_1 <- norm_mean_list
study1 <- norm_1[1:2, ]
study2 <- norm_1[3:4, ]
study3 <- norm_1[5:6, ]
study4 <- norm_1[7:8, ]
study5 <- norm_1[9:10, ]
study6 <- norm_1[11:12, ]
study7 <- norm_1[13:14, ]
studylist <- list(study1, study2, study3, study4, study5, study6, study7)
n = 0
for (stdy_n in studylist){
n = n + 1
# stdy_n <- stdy_n %>% select(condition, stroke_sum, PC) # select columns you want
studylist[[n]] <- stdy_n}
# paired t-test
summary_list <- list()
df <- data.frame(matrix(ncol = 8, nrow = 7))
colnames(df) <- c("study.ID", "p.value", "dgr.of.frd", "conf.int.lb", "conf.int.ub", "mean.diff", "std.err", "cohens.d")
i = 0
for (studies in studylist){
i = i + 1
# wide to long
studies <- melt(studies, id.vars = "condition")
studies <- arrange(studies, condition) #sorting by condition
# paired t-test
t_test <- t.test(value ~ condition,
data = studies,
paired = TRUE)
# effect size
efs <- cohensD(value ~ condition,
data   = studies,
method = "paired")
summaries <- capture.output(print(t_test), print(efs))
summary_list[[i]] <- summaries
df[i, 1] <- i
df[i, 2] <- t_test$p.value
df[i, 3] <- t_test$parameter
df[i, 4] <- t_test$conf.int[1]
df[i, 5] <- t_test$conf.int[2]
df[i, 6] <- t_test$estimate
df[i, 7] <- t_test$stderr
df[i, 8] <- efs
}
View(df)
library(metasens)
library(meta)
library(metafor)
# import data
meta <- read_csv("/Users/alex/Documents/GitHub/Visual-Similarity/analysis/meta.csv")
colnames(meta)[30] <- "visual.similarity"
colnames(meta)[31] <- "writing.system"
# replace Visual Similarity Index with results from VS analysis
meta[30] <- rev(df$cohens.d)
# meta[30] <- rev(df$diff)
# call the metacont random effect model
mod = metacont(
n.early,
mean.early.E64,
sd.early.E64,
n.late,
mean.late.E64,
sd.late.E64,
data = meta,
studlab = meta$author,
effect = "hedgesg",
method = "REML")
metacont()
?metacont()
mod = metacont(
n.early,
mean.early.E64,
sd.early.E64,
n.late,
mean.late.E64,
sd.late.E64,
data = meta,
studlab = meta$author,
method.smd = "Hedges",
method.bias = "Egger")
library(metasens)
library(meta)
library(metafor)
# import data
meta <- read_csv("/Users/alex/Documents/GitHub/Visual-Similarity/analysis/meta.csv")
colnames(meta)[30] <- "visual.similarity"
colnames(meta)[31] <- "writing.system"
# replace Visual Similarity Index with results from VS analysis
meta[30] <- rev(df$cohens.d)
# meta[30] <- rev(df$diff)
# call the metacont random effect model
mod = metacont(
n.early,
mean.early.E64,
sd.early.E64,
n.late,
mean.late.E64,
sd.late.E64,
data = meta,
studlab = meta$author,
method.smd = "Hedges",
method.bias = "Egger")
forest(mod)
MetaReg.vs <- metareg(mod, formula = ~ visual.similarity, method.tau = "REML", hakn = TRUE)
MetaReg.ws <- metareg(mod, formula = ~ writing.system, method.tau = "REML", hakn = TRUE)
MetaReg.vs
MetaReg.vs
View(mod)
?metareg
mod$sm
?rma
mod$TE
ggplot(data.frame(mod$TE.random, mod$n.e, mod$studlab),
aes(x = mod$TE.random, y = mod$n.e, label = mod$studlab)) +
geom_point(aes(size = exp(fit$coef[1] + fit$coef[2] * log(mod$n.e))),
shape = 21, fill = "blue", alpha = 0.7) +
geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
xlab("Study Effects") +
ylab("Sample Size") +
ggtitle("Meta-Regression Analysis") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
study_effects <- mod$TE.random
sample_sizes <- mod$n.e
study_labels <- mod$studlab
ggplot(data.frame(study_effects, sample_sizes, study_labels),
aes(x = study_effects, y = sample_sizes, label = study_labels)) +
geom_point(aes(size = exp(fit$coef[1] + fit$coef[2] * log(sample_sizes))),
shape = 21, fill = "blue", alpha = 0.7) +
geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
xlab("Study Effects") +
ylab("Sample Size") +
ggtitle("Meta-Regression Analysis") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
study_effects <- mod$TE.random
sample_sizes <- mod$n.e
study_labels <- mod$studlab
fit <- rma(yi = study_effects, vi = study_variances)
mod$seTE
study_effects <- mod$TE.random
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
mod$TE.random
mod$TE
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
ggplot(data.frame(study_effects, sample_sizes, study_labels),
aes(x = study_effects, y = sample_sizes, label = study_labels)) +
geom_point(aes(size = exp(fit$coef[1] + fit$coef[2] * log(sample_sizes))),
shape = 21, fill = "blue", alpha = 0.7) +
geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
xlab("Study Effects") +
ylab("Sample Size") +
ggtitle("Meta-Regression Analysis") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
ggplot(df, aes(x = study_effects, y = sample_sizes, label = study_labels)) +
geom_point(shape = 21, fill = "blue", alpha = 0.7) +
geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
xlab("Study Effects") +
ylab("Sample Size") +
ggtitle("Bubble Plot with Regression Line") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
xvals <- range(study_effects)
xvals <- c(xvals[1], xvals[2])
pred <- predict(fit, newx = data.frame(x = xvals), addx = TRUE)
ggplot(data.frame(study_effects, sample_sizes, study_labels),
aes(x = study_effects, y = sample_sizes, label = study_labels)) +
geom_point(aes(size = exp(fit$coef[1] + fit$coef[2] * log(sample_sizes))),
shape = 21, fill = "blue", alpha = 0.7) +
geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
geom_line(data = pred, aes(x = x, y = exp(fit$coef[1] + fit$coef[2] * log(exp(x))))) +
geom_ribbon(data = pred, aes(x = x, ymin = exp(fit$coef[1] + fit$coef[2] * log(exp(x))) - exp(fit$se[1] + fit$se[2] * log(exp(x))),
ymax = exp(fit$coef[1] + fit$coef[2] * log(exp(x))) + exp(fit$se[1] + fit$se[2] * log(exp(x)))), alpha = 0.3) +
xlab("Study Effects") +
ylab("Sample Size") +
ggtitle("Meta-Regression Analysis") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
# Make predictions for a range of sample sizes
pred <- predict(mod, n.e = 1:1000, type = "b", se.fit = TRUE)
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
ggplot(data.frame(study_effects, sample_sizes, study_labels),
aes(x = study_effects, y = sample_sizes, label = study_labels)) +
geom_point(size = 5, shape = 21, fill = "blue", alpha = 0.7) +
geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
xlab("Study Effects")
#
# ggplot(df, aes(x = study_effects, y = sample_sizes, label = study_labels)) +
#   geom_point(shape = 21, fill = "blue", alpha = 0.7) +
#   geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
#   geom_smooth(method = "lm", se = FALSE, color = "red") +
#   xlab("Study Effects") +
#   ylab("Sample Size") +
#   ggtitle("Bubble Plot with Regression Line") +
#   theme_bw() +
#   theme(plot.title = element_text(hjust = 0.5))
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
# Calculate regression line and confidence intervals
fit <- lm(study_effects ~ log(sample_sizes))
pred <- data.frame(study_effects = predict(fit), sample_sizes = exp(fit$coef[1] + fit$coef[2] * log(sample_sizes)))
pred_lower <- data.frame(study_effects = predict(fit, interval = "confidence")[,2], sample_sizes = exp(fit$coef[1] + fit$coef[2] * log(sample_sizes)))
pred_upper <- data.frame(study_effects = predict(fit, interval = "confidence")[,3], sample_sizes = exp(fit$coef[1] + fit$coef[2] * log(sample_sizes)))
# Plot bubble plot with regression line and CI
ggplot(data.frame(study_effects, sample_sizes, study_labels),
aes(x = study_effects, y = sample_sizes, label = study_labels)) +
geom_point(size = 5, shape = 21, fill = "blue", alpha = 0.7) +
geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
xlab("Study Effects") +
ylab("Sample Size") +
geom_line(data = pred, color = "red", size = 1.5) +
geom_ribbon(data = pred_lower, aes(ymin = study_effects, ymax = pred_lower$study_effects), alpha = 0.2) +
geom_ribbon(data = pred_upper, aes(ymin = pred_upper$study_effects, ymax = study_effects), alpha = 0.2) +
ggtitle("Meta-Regression Analysis") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
#
# ggplot(df, aes(x = study_effects, y = sample_sizes, label = study_labels)) +
#   geom_point(shape = 21, fill = "blue", alpha = 0.7) +
#   geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
#   geom_smooth(method = "lm", se = FALSE, color = "red") +
#   xlab("Study Effects") +
#   ylab("Sample Size") +
#   ggtitle("Bubble Plot with Regression Line") +
#   theme_bw() +
#   theme(plot.title = element_text(hjust = 0.5))
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
# Create a data frame with the study effects, sample sizes, and study labels
df <- data.frame(study_effects, sample_sizes, study_labels)
# Predict the expected study effect for each sample size
preds <- predict(mod, newmods = cbind(n = unique(df$sample_sizes)))
preds <- predict(mod, newmods = cbind(n = unique(df$sample_sizes)))
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
# Create a data frame with the study effects, sample sizes, and study labels
df <- data.frame(study_effects, sample_sizes, study_labels)
# Predict the expected study effect for each sample size
pred <- predictInterval(df, level=0.95, digits=3)
library(metasens)
library(meta)
library(metafor)
library(meta)
library(metafor)
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
# Create a data frame with the study effects, sample sizes, and study labels
df <- data.frame(study_effects, sample_sizes, study_labels)
# Predict the expected study effect for each sample size
pred <- predictInterval(df, level=0.95, digits=3)
install.packages("meta")
install.packages("meta")
install.packages("meta")
install.packages("meta")
install.packages("meta")
install.packages("meta")
knitr::opts_chunk$set(echo = TRUE)
library(meta)
library(metafor)
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE
fit <- rma(yi = study_effects, vi = study_variances)
# Create a data frame with the study effects, sample sizes, and study labels
df <- data.frame(study_effects, sample_sizes, study_labels)
# Predict the expected study effect for each sample size
pred <- predictInterval(df, level=0.95, digits=3)
