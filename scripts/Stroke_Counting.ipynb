{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/dkwbt3092rsgjhhmygyjjfqr0000gn/T/ipykernel_8187/1402898026.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  falseFont = np.array([[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n"
     ]
    }
   ],
   "source": [
    "import hangul_jamo\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "# stroke info\n",
    "choSeong = np.array(\n",
    "\t\t# [0x3131, 0x3132, 0x3134, 0x3137, 0x3138, 0x3139, 0x3141, 0x3142, 0x3143, 0x3145,\n",
    "\t\t# 0x3146, 0x3147, 0x3148, 0x3149, 0x314a, 0x314b, 0x314c, 0x314d, 0x314e], \n",
    "        [[\"ㄱ\", \"ㄲ\", \"ㄴ\", \"ㄷ\", \"ㄸ\", \"ㄹ\", \"ㅁ\", \"ㅂ\", \"ㅃ\", \"ㅅ\",\n",
    "\t\t\"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅉ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"], #choseong\n",
    "        [2, 4, 2, 3, 6, 5, 4, 4, 8, 2,\n",
    "\t\t4, 1, 3, 6, 4, 4, 4, 4, 3], #stroke\n",
    "\t\t[1, 2, 1, 2, 4, 4, 4, 4, 8, 1,\n",
    "\t\t2, 0, 2, 4, 2, 2, 3, 4, 0] ]) #junctions\n",
    "\n",
    "jungSeong = np.array(\n",
    "\t\t# [0x314f, 0x3150, 0x3151, 0x3152, 0x3153, 0x3154, 0x3155, 0x3156, 0x3157, 0x3158,\n",
    "\t\t# 0x3159, 0x315a, 0x315b, 0x315c, 0x315d, 0x315e, 0x315f, 0x3160, 0x3161, 0x3162,\n",
    "\t\t# 0x3163], \n",
    "        [[\"ㅏ\", \"ㅐ\", \"ㅑ\", \"ㅒ\", \"ㅓ\", \"ㅔ\", \"ㅕ\", \"ㅖ\", \"ㅗ\", \"ㅘ\",\n",
    "\t\t\"ㅙ\", \"ㅚ\", \"ㅛ\", \"ㅜ\", \"ㅝ\", \"ㅞ\", \"ㅟ\", \"ㅠ\", \"ㅡ\", \"ㅢ\",\n",
    "\t\t\"ㅣ\"], #jungseong\n",
    "        [2, 3, 3, 4, 2, 3, 3, 4, 2, 4,\n",
    "\t\t5, 3, 3, 2, 4, 5, 3, 3, 1, 2,\n",
    "\t\t1], #strokes\n",
    "\t\t[1, 2, 2, 4, 1, 1, 2, 2, 1, 2,\n",
    "\t\t3, 1, 2, 1, 2, 2, 1, 2, 0, 0,\n",
    "\t\t0]]) #junctions\n",
    "\n",
    "jongSeong = np.array(\n",
    "\t\t# [0x0000, 0x3131, 0x3132, 0x3133, 0x3134, 0x3135, 0x3136, 0x3137, 0x3139, 0x313a,\n",
    "\t\t# 0x313b, 0x313c, 0x313d, 0x313e, 0x313f, 0x3140, 0x3141, 0x3142, 0x3144, 0x3145,\n",
    "\t\t# 0x3146, 0x3147, 0x3148, 0x314a, 0x314b, 0x314c, 0x314d, 0x314e],\n",
    "        [[\"\", \"ㄱ\", \"ㄲ\", \"ㄳ\", \"ㄴ\", \"ㄵ\", \"ㄶ\", \"ㄷ\", \"ㄹ\", \"ㄺ\",\n",
    "\t\t\"ㄻ\", \"ㄼ\", \"ㄽ\", \"ㄾ\", \"ㄿ\", \"ㅀ\", \"ㅁ\", \"ㅂ\", \"ㅄ\", \"ㅅ\",\n",
    "\t\t\"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"], #jongseong\n",
    "        [0, 2, 4, 4, 2, 5, 5, 3, 5, 7,\n",
    "\t\t9, 9, 7, 9, 9, 8, 4, 4, 6, 2,\n",
    "\t\t4, 1, 3, 4, 3, 3, 4, 3], #strokes\n",
    "\t\t[0, 1, 2, 2, 1, 3, 1, 2, 4, 5,\n",
    "\t\t8, 8, 5, 7, 8, 4, 4, 4, 5, 1,\n",
    "\t\t2, 0, 2, 2, 2, 3, 4, 0]]) #junctions\n",
    "\n",
    "smallAlphabet = np.array([[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n",
    "\t\t\"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"ä\", \"ü\"], \n",
    "\t\t[2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 3, 1, 3,\n",
    "\t\t2, 1, 2, 2, 2, 1, 2, 2, 2, 4, 2, 2, 3, 4, 4], #strokes\n",
    "\t\t[2, 2, 0, 2, 2, 1, 2, 1, 2, 2, 3, 2, 2,\n",
    "\t\t1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1]]) #junctions\n",
    "\n",
    "bigAlphabet = np.array([[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n",
    "\t\t\"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"],\n",
    "\t\t[3, 3, 1, 2, 4, 3, 2, 3, 1, 1, 3, 1, 4,\n",
    "\t\t3, 1, 2, 2, 3, 1, 2, 1, 2, 4, 2, 3, 3], #strokes\n",
    "\t\t[3, 4, 0, 2, 3, 2, 2, 2, 2, 2, 3, 1, 3,\n",
    "\t\t2, 0, 2, 1, 3, 0, 1, 0, 1, 3, 1, 1, 2]]) #junctions\n",
    "symbol = np.array([[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"], \n",
    "\t\t[3, 4, 4, 4, 2, 4, 5, 5, 5, 1],\n",
    "\t\t[3, 4, 4, 4, 1, 4, 5, 5, 4, 0]])\n",
    "falseFont = np.array([[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n",
    "\t\t\"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"],\n",
    "\t\t[4, 5, 2, 5, 3, 6, 3, 3, 3, 3, 3, 3, 2, \n",
    "\t\t2, 3, 4, 4, 5, 3, 3, 2, 1, 3, 4, 4, 3, 2], \n",
    "\t\t[4, 4, 1, 6, 3, 4, 2, 3, 2, 2, 2, 1, 1,\n",
    "\t\t1, 4, 4, 5, 2, 2, 1, 0, 2, 3, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all sublists\n",
    "all = [choSeong, jungSeong, jongSeong, smallAlphabet, bigAlphabet]\n",
    "# all = [symbol, falseFont]\n",
    "str_list = []\n",
    "num_list = []\n",
    "num_list2 = []\n",
    "for el in all :\n",
    "    str_list += list(el[0])\n",
    "    num_list += list(el[1]) # list of strokes\n",
    "    num_list2 += list(el[2]) # list of junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Korean\n",
    "# read text file\n",
    "text = open('/Users/alex/Documents/GitHub/Visual-Similarity/OCR_results/Kor_4.txt', 'r')\n",
    "# save original text as a string\n",
    "\n",
    "# decompose hangul\n",
    "subcharacter = hangul_jamo.decompose(text.read())\n",
    "# original text\n",
    "ori_text = hangul_jamo.compose(subcharacter)\n",
    "ori_text = ori_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## English/German\n",
    "# read text file & get subcharactet(letters)\n",
    "with open('/Users/alex/Documents/GitHub/Visual-Similarity/OCR_results/Ger_4.txt', 'r') as file:\n",
    "    subcharacter = file.read().rstrip()\n",
    "# turn into list of strings\n",
    "ori_text = subcharacter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contents of symbols and put them into string\n",
    "cont = pd.read_csv('/Users/alex/Documents/GitHub/Visual-Similarity/results/pc_cont_4.csv')\n",
    "emp_list = []\n",
    "for i in range(len(cont['content'])):\n",
    "    emp_list.append(str(cont['content'][i]))\n",
    "subcharacter = \" \".join(emp_list)\n",
    "# turn into list of strings\n",
    "ori_text = subcharacter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subcomponents -> strokes\n",
    "stroke_list = []\n",
    "for str_i in subcharacter:\n",
    "    if str_i in str_list:\n",
    "        index = str_list.index(str_i)\n",
    "        stroke = num_list[index]\n",
    "        stroke_list.append(stroke)\n",
    "    else:\n",
    "        stroke_list.append(str_i)\n",
    "# subcomponents -> junctions\n",
    "junc_list = []\n",
    "for str_i in subcharacter:\n",
    "    if str_i in str_list:\n",
    "        index = str_list.index(str_i)\n",
    "        junction = num_list2[index]\n",
    "        junc_list.append(junction)\n",
    "    else:\n",
    "        junc_list.append(str_i)\n",
    "# turn nparr stroke_list into int list\n",
    "for i in range(len(stroke_list)):\n",
    "    if stroke_list[i] == ' ':\n",
    "        stroke_list[i] = '50'\n",
    "    elif stroke_list[i] == '空':\n",
    "        stroke_list[i] = '100'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "int_stroke_list = [int(i) for i in stroke_list]\n",
    "int_stroke_list.append(50) # add an 50 to the last character\n",
    "# turn nparr junc_list into int list\n",
    "for i in range(len(junc_list)):\n",
    "    if junc_list[i] == ' ':\n",
    "        junc_list[i] = '50'\n",
    "    elif junc_list[i] == '空':\n",
    "        junc_list[i] = '100'\n",
    "\n",
    "int_junc_list = [int(i) for i in junc_list]\n",
    "int_junc_list.append(50) # add an 50 to the last character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# object info summaries\n",
    "object_info = [list(v) for k,v in groupby(int_stroke_list, key = lambda x: x != 50) if k != 50]\n",
    "obj_sum = []\n",
    "for obj in object_info:\n",
    "    if obj != [50]:\n",
    "        obj_sum.append(obj)\n",
    "obj_num = []\n",
    "for ii in obj_sum:\n",
    "    obj_num.append(len(ii))\n",
    "# get number of disconnected strokes\n",
    "dscn_stroke = []\n",
    "dscn = 0\n",
    "for list_i in obj_sum:\n",
    "    for item in list_i:\n",
    "        if item == 1:\n",
    "            dscn += 1\n",
    "    dscn_stroke.append(dscn)\n",
    "    dscn = 0\n",
    "# get stroke sum of each character\n",
    "stroke_sum = []\n",
    "strokesum = 0\n",
    "for i in range(len(int_stroke_list)):\n",
    "    if int_stroke_list[i] != 50:\n",
    "        strokesum += int_stroke_list[i]\n",
    "    else:\n",
    "        stroke_sum.append(strokesum)\n",
    "        strokesum = 0\n",
    "# get junction sum of each character\n",
    "junc_sum = []\n",
    "juncsum = 0\n",
    "for i in range(len(int_junc_list)):\n",
    "    if int_junc_list[i] != 50:\n",
    "        juncsum += int_junc_list[i]\n",
    "    else:\n",
    "        junc_sum.append(juncsum)\n",
    "        juncsum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_4 = []\n",
    "for i in range(len(ori_text)):\n",
    "    list_4.append([ori_text[i], obj_num[i], dscn_stroke[i], stroke_sum[i], junc_sum[i]])\n",
    "df_4 = pd.DataFrame(list_4, columns=['content', 'obj_num', 'disconnected_stroke', 'stroke_sum', 'junc_sum'])\n",
    "df_4.to_csv('4_Ger.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary\n",
    "dict_5 = {i:[q, j, k, t] for i, q, j, k, t in zip(ori_text,obj_num, dscn_stroke, stroke_sum, junc_sum)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read excel file\n",
    "data_4 = pd.read_csv(r'/Users/alex/Documents/GitHub/Visual-Similarity/results/4_falsefont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_4 = pd.read_csv(r'/Users/alex/Documents/GitHub/Visual-Similarity/results/4_Ger.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_4 = pd.read_csv(r'/Users/alex/Documents/GitHub/Visual-Similarity/results/4_PC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_1 = pd.concat([data_4, data_w_4], axis=0)\n",
    "l_1.to_csv(\"4_a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2 = pd.concat([l_1, pc_4], axis=0)\n",
    "l_2.to_csv(\"4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_l_5 = list(data_3['ind'])\n",
    "pc_loc_l = list(pc_3['ind'])\n",
    "for loc in pc_loc_l:\n",
    "    if loc in loc_l_5:\n",
    "        ind = loc_l_5.index(loc)\n",
    "        ind_5 = pc_loc_l.index(loc)\n",
    "        data_5['perimetric_complexity'][ind] = pc_5['PC'][ind_5]\n",
    "\n",
    "data_5.to_csv('5.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_5_l = list(data_5['file_loc'])\n",
    "for key in pc_5['file_loc']:\n",
    "    if key in kor_5_l:\n",
    "        ind = kor_5_l.index(key)\n",
    "        data_5['vertices'][ind] = list_5[key][3]\n",
    "        data_5['disconnected_strokes'][ind] = list_5[key][1]\n",
    "data_5.to_csv('5_kc_Human.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472f3460692ba2c0861145e5e150d03c8a5c0e40e057944a047c431b9050b93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
