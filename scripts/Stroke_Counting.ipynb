{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hangul_jamo\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/dkwbt3092rsgjhhmygyjjfqr0000gn/T/ipykernel_85227/2493356691.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  jungSeong = np.array(\n"
     ]
    }
   ],
   "source": [
    "# stroke info\n",
    "choSeong = np.array(\n",
    "\t\t# [0x3131, 0x3132, 0x3134, 0x3137, 0x3138, 0x3139, 0x3141, 0x3142, 0x3143, 0x3145,\n",
    "\t\t# 0x3146, 0x3147, 0x3148, 0x3149, 0x314a, 0x314b, 0x314c, 0x314d, 0x314e], \n",
    "        [[\"ㄱ\", \"ㄲ\", \"ㄴ\", \"ㄷ\", \"ㄸ\", \"ㄹ\", \"ㅁ\", \"ㅂ\", \"ㅃ\", \"ㅅ\",\n",
    "\t\t\"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅉ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"], #choseong\n",
    "        [2, 4, 2, 3, 6, 5, 4, 4, 8, 2,\n",
    "\t\t4, 1, 3, 6, 4, 4, 4, 4, 3], #stroke\n",
    "\t\t[1, 2, 1, 2, 4, 4, 4, 4, 8, 1,\n",
    "\t\t2, 0, 2, 4, 2, 2, 3, 4, 0] ]) #junctions\n",
    "\n",
    "jungSeong = np.array(\n",
    "\t\t# [0x314f, 0x3150, 0x3151, 0x3152, 0x3153, 0x3154, 0x3155, 0x3156, 0x3157, 0x3158,\n",
    "\t\t# 0x3159, 0x315a, 0x315b, 0x315c, 0x315d, 0x315e, 0x315f, 0x3160, 0x3161, 0x3162,\n",
    "\t\t# 0x3163], \n",
    "        [[\"ㅏ\", \"ㅐ\", \"ㅑ\", \"ㅒ\", \"ㅓ\", \"ㅔ\", \"ㅕ\", \"ㅖ\", \"ㅗ\", \"ㅘ\",\n",
    "\t\t\"ㅙ\", \"ㅚ\", \"ㅛ\", \"ㅜ\", \"ㅝ\", \"ㅞ\", \"ㅟ\", \"ㅠ\", \"ㅡ\", \"ㅢ\",\n",
    "\t\t\"ㅣ\"], #jungseong\n",
    "        [2, 3, 3, 4, 2, 3, 3, 4, 2, 4,\n",
    "\t\t5, 3, 3, 2, 4, 5, 3, 3, 1, 2,\n",
    "\t\t1], #strokes\n",
    "\t\t[1, 2, 2, 4, 1, 1, 2, 2, 1, 2,\n",
    "\t\t3, 1, 2, 1, 2, 2, 1, 2, 0, 0]]) #junctions\n",
    "\n",
    "jongSeong = np.array(\n",
    "\t\t# [0x0000, 0x3131, 0x3132, 0x3133, 0x3134, 0x3135, 0x3136, 0x3137, 0x3139, 0x313a,\n",
    "\t\t# 0x313b, 0x313c, 0x313d, 0x313e, 0x313f, 0x3140, 0x3141, 0x3142, 0x3144, 0x3145,\n",
    "\t\t# 0x3146, 0x3147, 0x3148, 0x314a, 0x314b, 0x314c, 0x314d, 0x314e],\n",
    "        [[\"\", \"ㄱ\", \"ㄲ\", \"ㄳ\", \"ㄴ\", \"ㄵ\", \"ㄶ\", \"ㄷ\", \"ㄹ\", \"ㄺ\",\n",
    "\t\t\"ㄻ\", \"ㄼ\", \"ㄽ\", \"ㄾ\", \"ㄿ\", \"ㅀ\", \"ㅁ\", \"ㅂ\", \"ㅄ\", \"ㅅ\",\n",
    "\t\t\"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"], #jongseong\n",
    "        [0, 2, 4, 4, 2, 5, 5, 3, 5, 7,\n",
    "\t\t9, 9, 7, 9, 9, 8, 4, 4, 6, 2,\n",
    "\t\t4, 1, 3, 4, 3, 3, 4, 3], #strokes\n",
    "\t\t[0, 1, 2, 2, 1, 3, 1, 2, 4, 5,\n",
    "\t\t8, 8, 5, 7, 8, 4, 4, 4, 5, 1,\n",
    "\t\t2, 0, 2, 2, 2, 3, 4, 0]]) #junctions\n",
    "\n",
    "smallAlphabet = np.array([[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n",
    "\t\t\"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"ä\", \"ü\"], \n",
    "\t\t[2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 3, 1, 3,\n",
    "\t\t2, 1, 2, 2, 2, 1, 2, 2, 2, 4, 2, 2, 3, 4, 4], #strokes\n",
    "\t\t[2, 2, 0, 2, 2, 1, 2, 1, 2, 2, 3, 2, 2,\n",
    "\t\t1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1]]) #junctions\n",
    "\n",
    "bigAlphabet = np.array([[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n",
    "\t\t\"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"],\n",
    "\t\t[3, 3, 1, 2, 4, 3, 2, 3, 1, 1, 3, 1, 4,\n",
    "\t\t3, 1, 2, 2, 3, 1, 2, 1, 2, 4, 2, 3, 3], #strokes\n",
    "\t\t[3, 4, 0, 2, 3, 2, 2, 2, 2, 2, 3, 1, 3,\n",
    "\t\t2, 0, 2, 1, 3, 0, 1, 0, 1, 3, 1, 1, 2]]) #junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all sublists\n",
    "all = [choSeong, jungSeong, jongSeong, smallAlphabet, bigAlphabet]\n",
    "str_list = []\n",
    "num_list = []\n",
    "num_list2 = []\n",
    "for el in all :\n",
    "    str_list += list(el[0])\n",
    "    num_list += list(el[1])\n",
    "    num_list2 += list(el[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Korean\n",
    "# read text file\n",
    "text = open('/Users/alex/Documents/GitHub/Visual-Similarity/OCR_results/Kor_7.txt', 'r')\n",
    "# save original text as a string\n",
    "\n",
    "# decompose hangul\n",
    "subcharacter = hangul_jamo.decompose(text.read())\n",
    "# original text\n",
    "ori_text = hangul_jamo.compose(subcharacter)\n",
    "ori_text = ori_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## English/German\n",
    "# read text file & get subcharactet(letters)\n",
    "with open('/Users/alex/Documents/GitHub/Visual-Similarity/OCR_results/Ger_4.txt', 'r') as file:\n",
    "    subcharacter = file.read().rstrip()\n",
    "# turn into list of strings\n",
    "ori_text = subcharacter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subcomponents -> strokes\n",
    "stroke_list = []\n",
    "for str_i in subcharacter:\n",
    "    if str_i in str_list:\n",
    "        index = str_list.index(str_i)\n",
    "        stroke = num_list[index]\n",
    "        stroke_list.append(stroke)\n",
    "    else:\n",
    "        stroke_list.append(str_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subcomponents -> junctions\n",
    "junc_list = []\n",
    "for str_i in subcharacter:\n",
    "    if str_i in str_list:\n",
    "        index = str_list.index(str_i)\n",
    "        junction = num_list2[index]\n",
    "        junc_list.append(junction)\n",
    "    else:\n",
    "        junc_list.append(str_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn nparr stroke_list into int list\n",
    "for i in range(len(stroke_list)):\n",
    "    if stroke_list[i] == ' ':\n",
    "        stroke_list[i] = '50'\n",
    "    elif stroke_list[i] == '空':\n",
    "        stroke_list[i] = '100'\n",
    "\n",
    "int_stroke_list = [int(i) for i in stroke_list]\n",
    "int_stroke_list.append(50) # add an 50 to the last character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn nparr junc_list into int list\n",
    "for i in range(len(junc_list)):\n",
    "    if junc_list[i] == ' ':\n",
    "        junc_list[i] = '50'\n",
    "    elif junc_list[i] == '空':\n",
    "        junc_list[i] = '100'\n",
    "\n",
    "int_junc_list = [int(i) for i in junc_list]\n",
    "int_junc_list.append(50) # add an 50 to the last character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n"
     ]
    }
   ],
   "source": [
    "print(len(int_junc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object info summaries\n",
    "object_info = [list(v) for k,v in groupby(int_stroke_list, key = lambda x: x != 50) if k != 50]\n",
    "obj_sum = []\n",
    "for obj in object_info:\n",
    "    if obj != [50]:\n",
    "        obj_sum.append(obj)\n",
    "obj_num = []\n",
    "for ii in obj_sum:\n",
    "    obj_num.append(len(ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stroke sum of each character\n",
    "stroke_sum = []\n",
    "strokesum = 0\n",
    "for i in range(len(int_stroke_list)):\n",
    "    if int_stroke_list[i] != 50:\n",
    "        strokesum += int_stroke_list[i]\n",
    "    else:\n",
    "        stroke_sum.append(strokesum)\n",
    "        strokesum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get junction sum of each character\n",
    "junc_sum = []\n",
    "juncsum = 0\n",
    "for i in range(len(int_junc_list)):\n",
    "    if int_junc_list[i] != 50:\n",
    "        juncsum += int_junc_list[i]\n",
    "    else:\n",
    "        junc_sum.append(juncsum)\n",
    "        juncsum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OHR': [3, [1, 3, 3], 7, 4],\n",
       " 'BEIN': [4, [3, 4, 1, 3], 11, 4],\n",
       " 'KIND': [4, [3, 1, 3, 2], 9, 6],\n",
       " 'WORT': [4, [4, 1, 3, 2], 10, 3],\n",
       " 'MANN': [4, [4, 3, 3, 3], 13, 6],\n",
       " 'KNIE': [4, [3, 3, 1, 4], 11, 5],\n",
       " 'RAD': [3, [3, 3, 2], 8, 7],\n",
       " 'MILCH': [5, [4, 1, 1, 1, 3], 10, 11],\n",
       " 'PFERD': [5, [2, 3, 4, 3, 2], 14, 8],\n",
       " 'BOOT': [4, [3, 1, 1, 2], 7, 4],\n",
       " 'SPIEL': [5, [1, 2, 1, 4, 1], 9, 9],\n",
       " 'GELD': [4, [2, 4, 1, 2], 9, 10],\n",
       " 'HUT': [3, [3, 1, 2], 6, 3],\n",
       " 'TAG': [3, [2, 3, 2], 7, 6]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dictionary\n",
    "dict_4 = {i:[q, j, k, t] for i, q, j, k, t in zip(ori_text,obj_num, obj_sum, stroke_sum, junc_sum)}\n",
    "dict_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read excel file\n",
    "data_5 = pd.read_excel(r'/Users/alex/Documents/GitHub/Visual-Similarity/8_count_obj.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_8_l = list(data_8[0])\n",
    "for key in dict_korea_8:\n",
    "    if key in kor_8_l:\n",
    "        ind = kor_8_l.index(key)\n",
    "        data_8[1][ind] = dict_korea_8[key][1]\n",
    "data_8.to_csv('8_korean_Chinese_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_4)\n",
    "df = df.T\n",
    "df.to_excel('4_german221123.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472f3460692ba2c0861145e5e150d03c8a5c0e40e057944a047c431b9050b93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
