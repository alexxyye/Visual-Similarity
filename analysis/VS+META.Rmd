---
title: "Visual_Similarity&Meta_Analysis"
author: "Alex"
date: "2023-02-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Visual Similarity Analysis

```{r}
library(readr)
library(reshape2)
library(dplyr)
library(lsr)
library(ggplot2)
library(caret)
```

## Import raw data by condition

```{r}
# set cd
setwd("/Users/alex/Documents/GitHub/Visual-Similarity/results/final2/")

filelist <- list.files("./", pattern = "*.csv")
n = 0
df.filelist <- list()

for (file_n in filelist){
  n = n + 1
  df <- read_csv(file_n, col_types = cols(file_loc = col_skip()))
  df.filelist[[n]] <- df
}

split_into_2 <- function(df, loc, which_half){
  if (which_half == 1){
    df1 <- df[row.names(df) %in% 1:loc, ]
    return(df1)
  }
  else if (which_half == 2) {
    df2 <- df[row.names(df) %in% (loc+1):nrow(df), ]
    return(df2)
  }
  else {
    print("No Valid which_half input")
  }
}


```

## Prepare function

Max-min scaling normalization function

```{r}
normalize_df <- function(df) {
  # Find the maximum and minimum values for each column in the dataframe
  max_vals <- apply(df, 2, max)
  min_vals <- apply(df, 2, min)
  # Subtract the minimum value from each column
  df_sub <- sweep(df, 2, min_vals, `-`)
  # Divide each column by its range
  range_vals <- max_vals - min_vals
  df_normalized <- sweep(df_sub, 2, range_vals, `/`)
  return(df_normalized)
}
```

## Normalization

Now we change some steps in the raw data processing.\

**Possibility 1** (normalization after getting means from all conditions)\
The output is `norm_1`

```{r}
# split raw data by condition
symbol1 <- split_into_2(df.filelist[[1]], 60, 1)
german1 <- split_into_2(df.filelist[[1]], 60, 2)
symbol2 <- split_into_2(df.filelist[[2]], 60, 1)
english2 <- split_into_2(df.filelist[[2]], 60, 2)
symbol3 <- split_into_2(df.filelist[[3]], 59, 1)
english3 <-split_into_2(df.filelist[[3]], 59, 2)
falsefont4 <-split_into_2(df.filelist[[4]], 84, 1)
german4 <- split_into_2(df.filelist[[4]], 84, 2)
chinese5 <- split_into_2(df.filelist[[5]], 60, 1)
korean5 <- split_into_2(df.filelist[[5]], 60, 2)
chinese6 <- split_into_2(df.filelist[[6]], 40, 1)
korean6 <- split_into_2(df.filelist[[6]], 40, 2)
chinese7 <- split_into_2(df.filelist[[7]], 120, 1)
korean7 <- split_into_2(df.filelist[[7]], 120, 2)

# prepare a null mean list
mean_list <- data.frame(matrix(ncol = 6, nrow = 14))
colnames(mean_list) <- c("condition", "obj_num", "disc_strk", "strk_sum", "junc_sum", "PC")
mean_list$condition <- c('symbol1', 'german1', 'symbol2', 'english2', 'symbol3', 'english3', 
'falsefont4', 'german4', 'chinese5', 'korean5', 
'chinese6', 'korean6', 'chinese7', 'korean7')

# put all data together by condition
cond_list <- list(symbol1, german1, symbol2, english2, symbol3, english3, 
                  falsefont4, german4, chinese5, korean5, 
                  chinese6, korean6, chinese7, korean7)

for (cond_i in 1:14){
  for (col_j in 2:6){
    mean_ij <- mean(cond_list[[cond_i]][[col_j]])
    mean_list[cond_i, col_j] <- mean_ij
  }
}

# make a null normalized mean list
norm_mean_list <- data.frame(matrix(data = NA, nrow = 14, ncol = 6))
norm_mean_list[, 2:6] <- normalize_df(mean_list[ , 2:6])
colnames(norm_mean_list) <- c("condition", "obj_num", "disc_strk", "strk_sum", "junc_sum", "PC")
norm_mean_list$condition <- c('symbol1', 'german1', 'symbol2', 'english2', 'symbol3', 'english3', 
'falsefont4', 'german4', 'chinese5', 'korean5', 
'chinese6', 'korean6', 'chinese7', 'korean7')
norm_1 <- norm_mean_list
```

**Possibility 2** (normalization for each study, then get mean for each condition)\
Output: `norm_2`

```{r}
# prepare a null list holding normalizaed data for each study
norm_study_list <- list()
for (study_i in 1:7){
  ori <- df.filelist[[study_i]][, 1]
  norm_dat <- normalize_df(df.filelist[[study_i]][, 2:6])
  norm_study_list[[study_i]] <- cbind(ori, norm_dat)
}

# split into conditions
symbol1_norm <- split_into_2(norm_study_list[[1]], 60, 1)
german1_norm <- split_into_2(norm_study_list[[1]], 60, 2)
symbol2_norm <- split_into_2(norm_study_list[[2]], 60, 1)
english2_norm <- split_into_2(norm_study_list[[2]], 60, 2)
symbol3_norm <- split_into_2(norm_study_list[[3]], 59, 1)
english3_norm <-split_into_2(norm_study_list[[3]], 59, 2)
falsefont4_norm <-split_into_2(norm_study_list[[4]], 84, 1)
german4_norm <- split_into_2(norm_study_list[[4]], 84, 2)
chinese5_norm <- split_into_2(norm_study_list[[5]], 60, 1)
korean5_norm <- split_into_2(norm_study_list[[5]], 60, 2)
chinese6_norm <- split_into_2(norm_study_list[[6]], 40, 1)
korean6_norm <- split_into_2(norm_study_list[[6]], 40, 2)
chinese7_norm <- split_into_2(norm_study_list[[7]], 120, 1)
korean7_norm <- split_into_2(norm_study_list[[7]], 120, 2)
# make a normalized list
norm_cond_list <- list(symbol1_norm, german1_norm, symbol2_norm, english2_norm, symbol3_norm, english3_norm, falsefont4_norm, german4_norm, chinese5_norm, korean5_norm, chinese6_norm, korean6_norm, chinese7_norm, korean7_norm)

norm_mean_list <- data.frame(matrix(data = NA, nrow = 14, ncol = 6))
colnames(norm_mean_list) <- c("condition", "obj_num", "disc_strk", "strk_sum", "junc_sum", "PC")
norm_mean_list$condition <- c('symbol1', 'german1', 'symbol2', 'english2', 'symbol3', 'english3', 
'falsefont4', 'german4', 'chinese5', 'korean5', 
'chinese6', 'korean6', 'chinese7', 'korean7')
# calculate mean
for (cond_i in 1:14){
  for (col_j in 2:6){
        mean_ij <- mean(norm_cond_list[[cond_i]][[col_j]])
        norm_mean_list[cond_i, col_j] <- mean_ij
}
}

norm_2 <- norm_mean_list
```

**Possibility 3** (normalization for each condition, then get mean for each condition)\
Output: `norm_3`

```{r}
# split raw data by condition
symbol1 <- split_into_2(df.filelist[[1]], 60, 1)
german1 <- split_into_2(df.filelist[[1]], 60, 2)
symbol2 <- split_into_2(df.filelist[[2]], 60, 1)
english2 <- split_into_2(df.filelist[[2]], 60, 2)
symbol3 <- split_into_2(df.filelist[[3]], 59, 1)
english3 <-split_into_2(df.filelist[[3]], 59, 2)
falsefont4 <-split_into_2(df.filelist[[4]], 84, 1)
german4 <- split_into_2(df.filelist[[4]], 84, 2)
chinese5 <- split_into_2(df.filelist[[5]], 60, 1)
korean5 <- split_into_2(df.filelist[[5]], 60, 2)
chinese6 <- split_into_2(df.filelist[[6]], 40, 1)
korean6 <- split_into_2(df.filelist[[6]], 40, 2)
chinese7 <- split_into_2(df.filelist[[7]], 120, 1)
korean7 <- split_into_2(df.filelist[[7]], 120, 2)

# put all data together by condition
cond_list <- list(symbol1, german1, symbol2, english2, symbol3, english3, 
                  falsefont4, german4, chinese5, korean5, 
                  chinese6, korean6, chinese7, korean7)

# make a null normalized mean list
norm_mean_list <- data.frame(matrix(data = NA, nrow = 14, ncol = 6))
colnames(norm_mean_list) <- c("condition", "obj_num", "disc_strk", "strk_sum", "junc_sum", "PC")
norm_mean_list$condition <- c('symbol1', 'german1', 'symbol2', 'english2', 'symbol3', 'english3', 
'falsefont4', 'german4', 'chinese5', 'korean5', 
'chinese6', 'korean6', 'chinese7', 'korean7')

for (cond_i in 1:14){
  cond_raw_i <- (cond_list[[cond_i]])
  a <- normalize_df(cond_raw_i[, 2:6])
  b <- cond_raw_i[, 1]
  norm_cond_i <- cbind(b,a)
  for (col_j in 2:6){
    mean_i <- mean(norm_cond_i[, col_j])
    norm_mean_list[cond_i, col_j] <- mean_i
  }
}


norm_3 <- norm_mean_list
```

## Gather Data by Study

```{r}
study1 <- norm_1[1:2, ]
study2 <- norm_1[3:4, ]
study3 <- norm_1[5:6, ]
study4 <- norm_1[7:8, ]
study5 <- norm_1[9:10, ]
study6 <- norm_1[11:12, ]
study7 <- norm_1[13:14, ]


studylist <- list(study1, study2, study3, study4, study5, study6, study7)
n = 0
for (stdy_n in studylist){
  n = n + 1
  # stdy_n <- stdy_n %>% select(condition, stroke_sum, PC) # select columns you want
  studylist[[n]] <- stdy_n}
```

## Comparing data

### Paired t-test

```{r}
  # paired t-test
summary_list <- list()
df <- data.frame(matrix(ncol = 8, nrow = 7))
colnames(df) <- c("study.ID", "p.value", "dgr.of.frd", "conf.int.lb", "conf.int.ub", "mean.diff", "std.err", "cohens.d")
i = 0
for (studies in studylist){
  i = i + 1
  # wide to long
  studies <- melt(studies, id.vars = "condition")
  studies <- arrange(studies, condition) #sorting by condition
  # paired t-test
  t_test <- t.test(value ~ condition, 
                   data = studies, 
                   paired = TRUE)
  # effect size
  efs <- cohensD(value ~ condition,
                 data   = studies,
                 method = "paired")
  summaries <- capture.output(print(t_test), print(efs))
  summary_list[[i]] <- summaries
  df[i, 1] <- i
  df[i, 2] <- t_test$p.value
  df[i, 3] <- t_test$parameter
  df[i, 4] <- t_test$conf.int[1]
  df[i, 5] <- t_test$conf.int[2]
  df[i, 6] <- t_test$estimate
  df[i, 7] <- t_test$stderr
  df[i, 8] <- efs
}
```

### Simple difference (for single parameter)

```{r}
df <- data.frame(matrix(ncol = 2, nrow = 7))
colnames(df) <- c("study.ID", "diff")
para_name <- '' # !!!!!CHANGE PARAMETER NAME HERE!!!!!
for (n in 1:7){
  diff <- studylist[[n]][2, 2]-studylist[[n]][1, 2]
  df[n, 1] <- n
  df[n, 2] <- diff
}
```

# Meta-analysis

## Import packages

```{r}
library(meta)
library(metafor)
```

Compute a random model using SMD (Hedges' *g*), performing a bias test with Egger's test.

```{r}
# import data
meta <- read_csv("/Users/alex/Documents/GitHub/Visual-Similarity/analysis/meta.csv")
colnames(meta)[30] <- "visual.similarity"
colnames(meta)[31] <- "writing.system"

# replace Visual Similarity Index with results from VS analysis
# meta[30] <- rev(df$cohens.d)
meta[30] <- rev(df$diff)

# call the metacont random effect model
mod = metacont(
  n.early,
  mean.early.E64,
  sd.early.E64,
  n.late,
  mean.late.E64,
  sd.late.E64,
  data = meta,
  studlab = meta$author,
  method.smd = "Hedges",
  method.bias = "Egger")
```

## Meta-Regression

```{r}
MetaReg.vs <- metareg(mod, formula = ~ visual.similarity, method.tau = "REML", hakn = TRUE)
MetaReg.ws <- metareg(mod, formula = ~ writing.system, method.tau = "REML", hakn = TRUE)
MetaReg.vs
```

## Plots

Forest Plot

```{r}
forest(mod)
```

Bubble Plots

```{r}
study_effects <- mod$TE
sample_sizes <- mod$n.e
study_labels <- mod$studlab
study_variances <- mod$seTE

fit <- rma(yi = study_effects, vi = study_variances)

# Predict the fitted values
x_vals <- seq(min(sample_sizes), max(sample_sizes), length.out = 7)
y_vals <- predict(fit, newx = x_vals, level = 0.95, type = "response")

# # Plot the results
# ggplot(data.frame(study_effects, sample_sizes, study_labels), aes(x = sample_sizes, y = study_effects)) +
#   geom_point(aes(size = exp(fit$coef[1] + fit$coef[2] * log(sample_sizes))),
#              shape = 21, fill = "blue", alpha = 0.7) +
#   geom_text(aes(label = study_labels), check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
#   geom_smooth(aes(x = x_vals, y = y_vals$pred), se = TRUE, colour = "red", method = "lm") +
#   xlab("Sample Size") +
#   ylab("Study Effects") +
#   ggtitle("Meta-Regression Analysis") +
#   theme_bw() +
#   theme(plot.title = element_text(hjust = 0.5))
# 
ggplot(df, aes(x = study_effects, y = sample_sizes, label = study_labels)) +
  geom_point(shape = 21, fill = "blue", alpha = 0.7) +
  geom_text(check_overlap = TRUE, vjust = 1.5, hjust = 1.5) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  xlab("Study Effects") +
  ylab("Sample Size") +
  ggtitle("Bubble Plot with Regression Line") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```
